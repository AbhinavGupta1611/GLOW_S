{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82ec0ceb-4520-41d3-aeb3-56f2a48f6c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pwlf\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3b502a4-0744-482a-a3fa-d2df0df4b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "filename = 'ClimateRegionDivision/HUC_Parquet/allRegion_large_T273check_over60.parquet'\n",
    "final_large_data_warm_over60 = pd.read_parquet(filename)\n",
    "\n",
    "final_large_data_warm_over60 = final_large_data_warm_over60[final_large_data_warm_over60['width']>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42c24c98-1625-49e9-9d3d-35e2b10976c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(19190.61289939818)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_large_data_warm_over60['width'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cb5144-b716-4297-abc3-168b036ffa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:11<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load GLOW and GLOW-S points\n",
    "\n",
    "# Paths to the shapefiles\n",
    "lakes_shapefile_path = 'ClimateRegionDivision/HUC_Parquet/Large lakes 5km2 and Coastlunes/Large Hydrolakes 5km2.shp'\n",
    "coastline_shapefile_path = \"ClimateRegionDivision/HUC_Parquet/Large lakes 5km2 and Coastlunes/GSHHS_f_L1.shp\"\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "points_dataframes = []\n",
    "\n",
    "# Load and concatenate parquet files XS_GLOW_GLOWS_1 to XS_GLOW_GLOWS_8\n",
    "for i in tqdm(range(1, 9)):\n",
    "    file_path = f\"ClimateRegionDivision/HUC_Parquet/XS_GLOW_GLOWS_{i}.parquet\"\n",
    "    points_df = pd.read_parquet(file_path)\n",
    "    points_dataframes.append(points_df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "points_df = pd.concat(points_dataframes, ignore_index=True)\n",
    "\n",
    "# Convert points DataFrame to GeoDataFrame\n",
    "points_gdf = gpd.GeoDataFrame(\n",
    "    points_df, \n",
    "    geometry=[Point(xy) for xy in zip(points_df.lon, points_df.lat)],\n",
    "    crs=\"EPSG:4326\"  # Assuming the coordinate system is WGS84\n",
    ")\n",
    "\n",
    "print('Loaded shapefile and parquet files')\n",
    "\n",
    "# Load the lakes shapefile\n",
    "lakes_gdf = gpd.read_file(lakes_shapefile_path)\n",
    "\n",
    "# Load the coastline shapefile\n",
    "coastline_gdf = gpd.read_file(coastline_shapefile_path)\n",
    "\n",
    "# Ensure both GeoDataFrames have the same CRS as the points\n",
    "lakes_gdf = lakes_gdf.to_crs(points_gdf.crs)\n",
    "coastline_gdf = coastline_gdf.to_crs(points_gdf.crs)\n",
    "\n",
    "# Perform a spatial join to find points within lakes\n",
    "points_within_lakes = gpd.sjoin(points_gdf, lakes_gdf, predicate='within')\n",
    "\n",
    "# Inverse the spatial join result to get points outside lakes (on land)\n",
    "points_outside_lakes = points_gdf[~points_gdf.index.isin(points_within_lakes.index)]\n",
    "\n",
    "# Now perform a spatial join to find points that fall within the coastline features\n",
    "points_within_coastline = gpd.sjoin(points_outside_lakes, coastline_gdf, predicate='within')\n",
    "\n",
    "# Filter points to keep only those that fall within the coastline features\n",
    "# This ensures that the points are both outside lakes and within coastline features (land)\n",
    "points_on_land = points_within_coastline\n",
    "\n",
    "# Assign region based on 'riverID' by extracting the second character and converting to integer\n",
    "points_on_land['region'] = points_on_land['riverID'].str[1].astype(int)\n",
    "\n",
    "# Display the number of points within the coastline features\n",
    "points_on_land_count = points_on_land.shape[0]\n",
    "\n",
    "print(f\"Points on land (inside coastline features): {points_on_land_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05954712-4cf2-4bac-ba18-7f8c2d6a714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the final_large_data_warm_over60 based on COMIDs for which both GLOW and GLOW-S data are available\n",
    "points_on_land['COMID'] = points_on_land['ID_unique'].str.extract(r'R(\\d+)XS')\n",
    "COMID_we_have = set([int(i) for i in points_on_land['COMID'].unique()])\n",
    "final_large_data_warm_over60_inCOMID = final_large_data_warm_over60[final_large_data_warm_over60['COMID'].isin(COMID_we_have)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0175e2ee-13d1-4156-b8c8-f4691f081d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_large_data_warm_over60_inCOMID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc65400-659a-49c7-8722-b58d01c2d1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename date_x to date_YMD to merge\n",
    "points_on_land = points_on_land.rename(columns={'date_x': 'date_YMD'})\n",
    "\n",
    "# Convert COMID to int\n",
    "points_on_land['COMID'] = points_on_land['COMID'].astype(int)\n",
    "\n",
    "final_large_data_warm_over60_inCOMID['ID_date'] = final_large_data_warm_over60_inCOMID['riverID'] + final_large_data_warm_over60_inCOMID['date_YMD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b3fa5a-d8e1-4c86-83f0-4d333fbb0491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 'Points on land' and 'final_large_data_warm_over60_inCOMID'\n",
    "final_large_data_warm_over60_inCOMID_land = pd.merge(\n",
    "    points_on_land,\n",
    "    final_large_data_warm_over60_inCOMID[['COMID','date_YMD', 'ID_date', 'hot_enough']],\n",
    "    on=['ID_date'],\n",
    "    how='inner'  # Change to 'left' or 'right' if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca80fefa-6a6b-4a60-aef8-3cff55f65f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_large_data_warm_over60_inCOMID_land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080d6854-9d75-4afa-930f-40a23b4b6bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the GLOW-S measurements below 10m and all the GLOW measurements below 30m\n",
    "final_large_data_warm_over60_inCOMID_land = final_large_data_warm_over60_inCOMID_land[(final_large_data_warm_over60_inCOMID_land['width_x']>10) & (final_large_data_warm_over60_inCOMID_land['width_y']>30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb241a2-296f-436f-bec1-eb27be5eede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import binned_statistic_2d\n",
    "\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# Plot data\n",
    "x = final_large_data_warm_over60_inCOMID_land['width_x'].values\n",
    "y = final_large_data_warm_over60_inCOMID_land['width_y'].values\n",
    "\n",
    "hb = plt.hexbin(x, y, gridsize=100, cmap='viridis', bins='log', alpha=1)\n",
    "\n",
    "# Perform linear regression on the original x, y data\n",
    "model = sklearn.linear_model.LinearRegression()\n",
    "model.fit(x.reshape(-1, 1), y.reshape(-1, 1))\n",
    "slope = model.coef_[0][0]\n",
    "intercept = model.intercept_[0]\n",
    "r2 = sklearn.metrics.r2_score(y.reshape(-1, 1), intercept + slope*x.reshape(-1, 1))\n",
    "\n",
    "# Define points for the regression line within the specified range\n",
    "x_regression_points = np.array([0, 7000])\n",
    "y_regression_points = slope * x_regression_points + intercept\n",
    "\n",
    "# Plot the regression line\n",
    "plt.plot(x_regression_points, y_regression_points, color='red', linewidth=1.5)\n",
    "plt.title(f'y = {slope:.2f}x + {intercept:.2f} (R$^{2}$ = {r2:.2f})', fontsize=14, verticalalignment='top', color='black', fontweight='bold')\n",
    "\n",
    "cb = plt.colorbar(hb, pad=0.02)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('GLOW-S width (m)', fontweight='bold')\n",
    "plt.ylabel('GLOW width (m)', fontweight='bold')\n",
    "\n",
    "# Set equal scaling, limits, and grid\n",
    "plt.xlim(0, 7000)  # Limit x-axis range\n",
    "plt.ylim(0, 7000)  # Limit y-axis range\n",
    "plt.plot([0, 7000], [0, 7000], color='black')\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.7, color='lightgray')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('/N/lustre/project/proj-212/abhinav/River_Width_analysis/RiverWidthAnalysis/Final_Figures/GLOW_vs_GLOWS_linear.tiff', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65be82a-95fa-4a81-9797-4c75ba287768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import binned_statistic_2d\n",
    "\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# Plot data\n",
    "x = final_large_data_warm_over60_inCOMID_land['width_x'].values\n",
    "y = final_large_data_warm_over60_inCOMID_land['width_y'].values\n",
    "\n",
    "x_log = np.log10(x)\n",
    "y_log = np.log10(y)\n",
    "\n",
    "hb = plt.hexbin(x_log, y_log, gridsize=100, cmap='viridis', bins='log', alpha=1)\n",
    "\n",
    "# Perform linear regression on the original x, y data\n",
    "model = sklearn.linear_model.LinearRegression()\n",
    "model.fit(x_log.reshape(-1, 1), y_log.reshape(-1, 1))\n",
    "slope = model.coef_[0][0]\n",
    "intercept = model.intercept_[0]\n",
    "r2 = sklearn.metrics.r2_score(y_log.reshape(-1, 1), intercept + slope*x_log.reshape(-1, 1))\n",
    "\n",
    "# Define points for the regression line within the specified range\n",
    "x_regression_points = np.array([0, 7000])\n",
    "y_regression_points = slope * x_regression_points + intercept\n",
    "\n",
    "# Plot the regression line\n",
    "plt.plot(x_regression_points, y_regression_points, color='red', linewidth=1.5)\n",
    "plt.title(f'y = {slope:.2f}x + {intercept:.2f} (R$^{2}$ = {r2:.2f})', fontsize=14, verticalalignment='top', color='black', fontweight='bold')\n",
    "\n",
    "cb = plt.colorbar(hb, pad=0.02)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('log10(GLOW-S width (m))', fontweight='bold')\n",
    "plt.ylabel('log10(GLOW width (m))', fontweight='bold')\n",
    "\n",
    "# Set equal scaling, limits, and grid\n",
    "plt.xlim(1, 4)  # Limit x-axis range\n",
    "plt.ylim(1, 4)  # Limit y-axis range\n",
    "plt.plot([0, 4], [0, 4], color='black')\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.7, color='lightgray')\n",
    "\n",
    "# Show plot\n",
    "plt.savefig('/N/lustre/project/proj-212/abhinav/River_Width_analysis/RiverWidthAnalysis/Final_Figures/GLOW_vs_GLOWS_log10.tiff', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a269b89d-09d4-4eec-adc9-8bfe9d50c6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "# Latitude ranges to filter data\n",
    "lat_ranges = [(60, 90), (30, 60), (0, 30), (-30, 0), (-60, -30)]\n",
    "range_labels = ['60 to 90', '30 to 60', '0 to 30', '-30 to 0', '-60 to -30']\n",
    "\n",
    "# Create a 2x3 grid for subplots (5 plots)\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.size'] = 14\n",
    "fig, axes = plt.subplots(2, 3, figsize=(13, 8))\n",
    "axes = axes.ravel()  # Flatten to easily iterate\n",
    "\n",
    "# Set global x and y axis limits\n",
    "x_lim = (0, 7000)\n",
    "y_lim = (0, 7000)\n",
    "\n",
    "# Iterate over latitude ranges and plot\n",
    "for i, lat_range in enumerate(lat_ranges):\n",
    "    # Filter data within the current latitude range\n",
    "    filtered_data = final_large_data_warm_over60_inCOMID_land[(final_large_data_warm_over60_inCOMID_land['lat'] >= lat_range[0]) & \n",
    "                                                               (final_large_data_warm_over60_inCOMID_land['lat'] < lat_range[1])]\n",
    "    \n",
    "    x_widths = filtered_data['width_x'].values\n",
    "    y_widths = filtered_data['width_y'].values\n",
    "    \n",
    "    # Perform linear regression on filtered data\n",
    "    model = sklearn.linear_model.LinearRegression()\n",
    "    model.fit(x_widths.reshape(-1, 1), y_widths.reshape(-1, 1))\n",
    "    slope = model.coef_[0][0]\n",
    "    intercept = model.intercept_[0]\n",
    "    r2 = sklearn.metrics.r2_score(y_widths.reshape(-1, 1), intercept + slope*x_widths.reshape(-1, 1))\n",
    "\n",
    "    x_reg_line_points = np.array([0, 7000])\n",
    "    y_reg_line_points = slope * x_reg_line_points + intercept\n",
    "    \n",
    "    # Plot the hexbin plot on the current axis\n",
    "    ax = axes[i]\n",
    "    hb = ax.hexbin(x_widths, y_widths, gridsize=100, cmap='viridis', bins='log')\n",
    "    ax.plot([0, 7000], [0, 7000], color='black')\n",
    "    \n",
    "    # Plot the regression line\n",
    "    print(intercept)\n",
    "    if intercept > 0:\n",
    "        ax.plot(x_reg_line_points, y_reg_line_points, color='red', linewidth=1, \n",
    "                label=f'Regression: y = {slope:.2f}x + {intercept:.2f}\\n$R^2$ = {r2:.2f}')\n",
    "    else:\n",
    "        ax.plot(x_reg_line_points, y_reg_line_points, color='red', linewidth=1, \n",
    "                label=f'Regression: y = {slope:.2f}x - {abs(intercept):.2f}\\n$R^2$ = {r2:.2f}')\n",
    "    \n",
    "    \n",
    "    # Add regression equation as text within the plot\n",
    "    ax.text(0.05, 0.95, f'y = {slope:.2f}x + {intercept:.2f}\\n$R^2$ = {r2:.2f}',\n",
    "            transform=ax.transAxes, fontsize=11, verticalalignment='top', color='black')\n",
    "    \n",
    "    # Add title and set aspect\n",
    "    ax.set_title(f'Latitude Range: {range_labels[i]}', fontsize=13, fontweight='bold')\n",
    "    ax.set_xlim(x_lim)\n",
    "    ax.set_ylim(y_lim)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.7, color='lightgray')\n",
    "    \n",
    "    # Set locators for consistent intervals\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "fig.text(0.08, 0.5, 'GLOW width (m)', va='center', rotation='vertical', fontweight='bold')\n",
    "fig.text(0.5, 0.04, 'GLOW-S width (m)', ha='center', fontweight='bold')\n",
    "\n",
    "# Hide the unused subplot (6th plot in 2x3 grid)\n",
    "axes[-1].axis('off')\n",
    "\n",
    "# Add a common color bar for all plots\n",
    "cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])  # Position of color bar\n",
    "cb = fig.colorbar(hb, cax=cbar_ax)\n",
    "cb.set_label('Number of Observations (log scale)')\n",
    "\n",
    "# Adjust layout for spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.3)\n",
    "\n",
    "# Show the plots\n",
    "plt.savefig('/N/lustre/project/proj-212/abhinav/River_Width_analysis/RiverWidthAnalysis/Final_Figures/GLOW_vs_GLOWS_latitude.tiff', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9319e210-fe1e-4d92-9566-8c1b30f5ed5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
